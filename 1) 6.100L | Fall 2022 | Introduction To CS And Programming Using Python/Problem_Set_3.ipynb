{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KPQr2dOYVr1HoSBv-Qgr9Jh2kOh7Ra3M",
      "authorship_tag": "ABX9TyNnNPP39lnJEIaGlcmHPZSe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChanMin02/Self-Study/blob/main/1)%206.100L%20%7C%20Fall%202022%20%7C%20Introduction%20To%20CS%20And%20Programming%20Using%20Python/Problem_Set_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ2CLHoBIVYy",
        "outputId": "0a919e6e-ce6c-4136-a327-6e7fc35c069a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('hello', 0.0), ('world', 0.10034333188799373)]\n"
          ]
        }
      ],
      "source": [
        "# 6.100A Fall 2022\n",
        "# Problem Set 3\n",
        "# Written by: sylvant, muneezap, charz, anabell, nhung, wang19k, asinelni, shahul, jcsands\n",
        "\n",
        "# Problem Set 3\n",
        "# Name:\n",
        "# Collaborators:\n",
        "\n",
        "# Purpose: Check for similarity between two texts by comparing different kinds of word statistics.\n",
        "\n",
        "import string\n",
        "import math\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "### DO NOT MODIFY THIS FUNCTION\n",
        "def load_file(filename):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        filename: string, name of file to read\n",
        "    Returns:\n",
        "        string, contains file contents\n",
        "    \"\"\"\n",
        "    # print(\"Loading file %s\" % filename)\n",
        "    inFile = open(filename, 'r')\n",
        "    line = inFile.read().strip()\n",
        "    for char in string.punctuation:\n",
        "        line = line.replace(char, \"\")\n",
        "    inFile.close()\n",
        "    return line.lower()\n",
        "\n",
        "\n",
        "### Problem 0: Prep Data ###\n",
        "def text_to_list(input_text):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        input_text: string representation of text from file.\n",
        "                    assume the string is made of lowercase characters\n",
        "    Returns:\n",
        "        list representation of input_text, where each word is a different element in the list\n",
        "    \"\"\"\n",
        "    return re.split('[ \\n]+',input_text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Problem 1: Get Frequency ###\n",
        "def get_frequencies(input_iterable):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        input_iterable: a string or a list of strings, all are made of lowercase characters\n",
        "    Returns:\n",
        "        dictionary that maps string:int where each string\n",
        "        is a letter or word in input_iterable and the corresponding int\n",
        "        is the frequency of the letter or word in input_iterable\n",
        "    Note:\n",
        "        You can assume that the only kinds of white space in the text documents we provide will be new lines or space(s) between words (i.e. there are no tabs)\n",
        "    \"\"\"\n",
        "\n",
        "    return dict(Counter(input_iterable))\n",
        "\n",
        "\n",
        "### Problem 2: Letter Frequencies ###\n",
        "def get_letter_frequencies(word):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        word: word as a string\n",
        "    Returns:\n",
        "        dictionary that maps string:int where each string\n",
        "        is a letter in word and the corresponding int\n",
        "        is the frequency of the letter in word\n",
        "    \"\"\"\n",
        "    letter_frequencies = {}\n",
        "\n",
        "    for char in word:\n",
        "      if char in letter_frequencies.keys():\n",
        "        letter_frequencies[char] += 1\n",
        "\n",
        "      else:\n",
        "        letter_frequencies[char] = 1\n",
        "\n",
        "    return letter_frequencies\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Problem 3: Similarity ###\n",
        "def calculate_similarity_score(freq_dict1, freq_dict2):\n",
        "    \"\"\"\n",
        "    The keys of dict1 and dict2 are all lowercase,\n",
        "    you will NOT need to worry about case sensitivity.\n",
        "\n",
        "    Args:\n",
        "        freq_dict1: frequency dictionary of letters of word1 or words of text1\n",
        "        freq_dict2: frequency dictionary of letters of word2 or words of text2\n",
        "    Returns:\n",
        "        float, a number between 0 and 1, inclusive\n",
        "        representing how similar the words/texts are to each other\n",
        "\n",
        "        The difference in words/text frequencies = DIFF sums words\n",
        "        from these three scenarios:\n",
        "        * If an element occurs in dict1 and dict2 then\n",
        "          get the difference in frequencies\n",
        "        * If an element occurs only in dict1 then take the\n",
        "          frequency from dict1\n",
        "        * If an element occurs only in dict2 then take the\n",
        "          frequency from dict2\n",
        "         The total frequencies = ALL is calculated by summing\n",
        "         all frequencies in both dict1 and dict2.\n",
        "        Return 1-(DIFF/ALL) rounded to 2 decimal places\n",
        "    \"\"\"\n",
        "    keys = set.union(set(freq_dict1.keys()),set(freq_dict2.keys()))\n",
        "\n",
        "    DIFF = 0\n",
        "    ALL = 0\n",
        "\n",
        "    for key in keys:\n",
        "      if key in freq_dict1.keys() and key in freq_dict2.keys():\n",
        "        DIFF += abs(freq_dict1[key] - freq_dict2[key])\n",
        "        ALL += freq_dict1[key] + freq_dict2[key]\n",
        "\n",
        "      elif key in freq_dict1.keys() and key not in freq_dict2.keys():\n",
        "        DIFF += abs(freq_dict1[key])\n",
        "        ALL += freq_dict1[key]\n",
        "\n",
        "      else:\n",
        "        DIFF += abs(freq_dict2[key])\n",
        "        ALL += freq_dict2[key]\n",
        "\n",
        "    return 1-(DIFF/ALL)\n",
        "\n",
        "\n",
        "### Problem 4: Most Frequent Word(s) ###\n",
        "def get_most_frequent_words(freq_dict1, freq_dict2):\n",
        "    \"\"\"\n",
        "    The keys of dict1 and dict2 are all lowercase,\n",
        "    you will NOT need to worry about case sensitivity.\n",
        "\n",
        "    Args:\n",
        "        freq_dict1: frequency dictionary for one text\n",
        "        freq_dict2: frequency dictionary for another text\n",
        "    Returns:\n",
        "        list of the most frequent word(s) in the input dictionaries\n",
        "\n",
        "    The most frequent word:\n",
        "        * is based on the combined word frequencies across both dictionaries.\n",
        "          If a word occurs in both dictionaries, consider the sum the\n",
        "          freqencies as the combined word frequency.\n",
        "        * need not be in both dictionaries, i.e it can be exclusively in\n",
        "          dict1, dict2, or shared by dict1 and dict2.\n",
        "    If multiple words are tied (i.e. share the same highest frequency),\n",
        "    return an alphabetically ordered list of all these words.\n",
        "    \"\"\"\n",
        "    words = dict(Counter(freq_dict1) + Counter(freq_dict2))\n",
        "\n",
        "    return [key for key,value in words.items() if max(words.values()) == value]\n",
        "\n",
        "\n",
        "### Problem 5: Finding TF-IDF ###\n",
        "def get_tf(file_path):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        file_path: name of file in the form of a string\n",
        "    Returns:\n",
        "        a dictionary mapping each word to its TF\n",
        "\n",
        "    * TF is calculatd as TF(i) = (number times word *i* appears\n",
        "        in the document) / (total number of words in the document)\n",
        "    * Think about how we can use get_frequencies from earlier\n",
        "    \"\"\"\n",
        "    text = get_frequencies(text_to_list(load_file(file_path)))\n",
        "\n",
        "    return {key : text[key]/sum(text.values()) for key in text.keys() }\n",
        "\n",
        "\n",
        "def get_idf(file_paths):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        file_paths: list of names of files, where each file name is a string\n",
        "    Returns:\n",
        "       a dictionary mapping each word to its IDF\n",
        "\n",
        "    * IDF is calculated as IDF(i) = log_10(total number of documents / number of\n",
        "    documents with word *i* in it), where log_10 is log base 10 and can be called\n",
        "    with math.log10()\n",
        "\n",
        "    \"\"\"\n",
        "    word_file_count ={}\n",
        "\n",
        "    for file in file_paths:\n",
        "      for word in set(text_to_list(load_file(file))):\n",
        "        if word in word_file_count.keys():\n",
        "          word_file_count[word] += 1\n",
        "\n",
        "        else :\n",
        "          word_file_count[word] = 1\n",
        "\n",
        "    return {key:math.log10(len(file_paths)/word_file_count[key]) for key in word_file_count.keys() }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_tfidf(tf_file_path, idf_file_paths):\n",
        "    \"\"\"\n",
        "        Args:\n",
        "            tf_file_path: name of file in the form of a string (used to calculate TF)\n",
        "            idf_file_paths: list of names of files, where each file name is a string\n",
        "            (used to calculate IDF)\n",
        "        Returns:\n",
        "           a sorted list of tuples (in increasing TF-IDF score), where each tuple is\n",
        "           of the form (word, TF-IDF). In case of words with the same TF-IDF, the\n",
        "           words should be sorted in increasing alphabetical order.\n",
        "\n",
        "        * TF-IDF(i) = TF(i) * IDF(i)\n",
        "        \"\"\"\n",
        "    tf_dict = get_tf(tf_file_path)\n",
        "    idf_dict = get_idf(idf_file_paths)\n",
        "\n",
        "    return [(word,tf_dict[word]*idf_dict[word]) for word in tf_dict.keys()]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pass\n",
        "    ###############################################################\n",
        "    ## Uncomment the following lines to test your implementation ##\n",
        "    ###############################################################\n",
        "\n",
        "    # # Tests Problem 0: Prep Data\n",
        "    # test_directory = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "    # hello_world, hello_friend = load_file(test_directory + 'hello_world.txt'), load_file(test_directory + 'hello_friends.txt')\n",
        "    # world, friend = text_to_list(hello_world), text_to_list(hello_friend)\n",
        "    # print(world)      # should print ['hello', 'world', 'hello']\n",
        "    # print(friend)     # should print ['hello', 'friends']\n",
        "\n",
        "    # # Tests Problem 1: Get Frequencies\n",
        "    # test_directory = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "    # hello_world, hello_friend = load_file(test_directory + 'hello_world.txt'), load_file(test_directory + 'hello_friends.txt')\n",
        "    # world, friend = text_to_list(hello_world), text_to_list(hello_friend)\n",
        "    # world_word_freq = get_frequencies(world)\n",
        "    # friend_word_freq = get_frequencies(friend)\n",
        "    # print(world_word_freq)    # should print {'hello': 2, 'world': 1}\n",
        "    # print(friend_word_freq)   # should print {'hello': 1, 'friends': 1}\n",
        "\n",
        "    # # Tests Problem 2: Get Letter Frequencies\n",
        "    # freq1 = get_letter_frequencies('hello')\n",
        "    # freq2 = get_letter_frequencies('that')\n",
        "    # print(freq1)      #  should print {'h': 1, 'e': 1, 'l': 2, 'o': 1}\n",
        "    # print(freq2)      #  should print {'t': 2, 'h': 1, 'a': 1}\n",
        "\n",
        "    # # Tests Problem 3: Similarity\n",
        "    # test_directory = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "    # hello_world, hello_friend = load_file(test_directory + 'hello_world.txt'), load_file(test_directory + 'hello_friends.txt')\n",
        "    # world, friend = text_to_list(hello_world), text_to_list(hello_friend)\n",
        "    # world_word_freq = get_frequencies(world)\n",
        "    # friend_word_freq = get_frequencies(friend)\n",
        "    # word1_freq = get_letter_frequencies('toes')\n",
        "    # word2_freq = get_letter_frequencies('that')\n",
        "    # word3_freq = get_frequencies('nah')\n",
        "    # word_similarity1 = calculate_similarity_score(word1_freq, word1_freq)\n",
        "    # word_similarity2 = calculate_similarity_score(word1_freq, word2_freq)\n",
        "    # word_similarity3 = calculate_similarity_score(word1_freq, word3_freq)\n",
        "    # word_similarity4 = calculate_similarity_score(world_word_freq, friend_word_freq)\n",
        "    # print(word_similarity1)       # should print 1.0\n",
        "    # print(word_similarity2)       # should print 0.25\n",
        "    # print(word_similarity3)       # should print 0.0\n",
        "    # print(word_similarity4)       # should print 0.4\n",
        "\n",
        "    # # Tests Problem 4: Most Frequent Word(s)\n",
        "    # freq_dict1, freq_dict2 = {\"hello\": 5, \"world\": 1}, {\"hello\": 1, \"world\": 5}\n",
        "    # most_frequent = get_most_frequent_words(freq_dict1, freq_dict2)\n",
        "    # print(most_frequent)      # should print [\"hello\", \"world\"]\n",
        "\n",
        "    # Tests Problem 5: Find TF-IDF\n",
        "    tf_text_file = '/content/drive/MyDrive/Colab Notebooks/hello_world.txt'\n",
        "    idf_text_files = ['/content/drive/MyDrive/Colab Notebooks/hello_world.txt', '/content/drive/MyDrive/Colab Notebooks/hello_friends.txt']\n",
        "    tf = get_tf(tf_text_file)\n",
        "    idf = get_idf(idf_text_files)\n",
        "    tf_idf = get_tfidf(tf_text_file, idf_text_files)\n",
        "    # print(tf)     # should print {'hello': 0.6666666666666666, 'world': 0.3333333333333333}\n",
        "    # print(idf)    # should print {'hello': 0.0, 'world': 0.3010299956639812, 'friends': 0.3010299956639812}\n",
        "    print(tf_idf) # should print [('hello', 0.0), ('world', 0.10034333188799373)]"
      ]
    }
  ]
}